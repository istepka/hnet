# config.yaml
# Hydra configuration file for train.py

defaults:
  - _self_
  - override hydra/job_logging: disabled # No fluff
  - override hydra/hydra_logging: disabled # No fluff

hydra:
  run:
    dir: ./outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}

paths:
  project_root: /home/${oc.env:USER}/hnet
  scratch_dir: /home/scratch/${oc.env:USER}
  data_dir: /data/user_data/${oc.env:USER}/data/hnet
  checkpoint_save_path: /data/user_data/${oc.env:USER}/checkpoints
  experiment_dir: ${paths.data_dir}/experiments
  model_cache: ${paths.scratch_dir}/model_cache
  hf_cache: /data/hf_cache

model:
  stages: 2
  size: L
  config_path: "configs/hnet_${model.stages}stage_${model.size}.json"

data:
  name: wikitext
  input_len: 512 # Input sequence length / context size
  batch_size: 64 # Batch size for training, 128 x 256 fits on L40s GPU 
  num_workers: 2
  pin_memory: false
  shuffle: true
  regenerate_tokens: false
  ag_news:
    path: ag_news 
    name: null
  wikitext:
    path: Salesforce/wikitext
    name: wikitext-103-v1
    
  

name: hnet_${data.name}_${model.stages}stage_${model.size}

optimizer:
  base_lr: 6.25e-4
  weight_decay: 0.1
  lr_multipliers: [2.0, 1.5, 1.0]   # [Stage 0, Stage 1, Main Network]

training:
  device: cuda
  total_steps: 1000 # Total training steps (batches)
  log_every: 50 # Log training metrics every N steps
  alpha: 0.03 # Ratio loss weight
  n_ratios: [3, 3]  # N ratios for [Stage 0, Stage 1]
  save_every: 500  # Save checkpoint every N steps

plotting:
  plot_sentences: 
    - The quick brown fox jumps over the lazy dog.
    - Wikipedia is a free online encyclopedia that aims to provide.
    - Artificial intelligence is transforming the world in many ways.
    - kabksbklbfieugf uiahefwuhl aleuhu evjhl hiseualghfiueigu
    - ababababababababababababababababababababababababababa
    - ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab 
    - aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa